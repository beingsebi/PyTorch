
# [00. PyTorch Fundamentals](https://www.learnpytorch.io/00_pytorch_fundamentals/)
This is me documenting the process of learning ML & AI using PyTorch. I'm going to note here what I find most interesting.

---------------- 

### Useful links:

- [The guide i'm following](https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb) 
- [Github link ](https://github.com/mrdbourke/pytorch-deep-learning)
- [Discussions page](https://github.com/mrdbourke/pytorch-deep-learning/discussions)
- [PyTorch forum](https://discuss.pytorch.org/)
- [PyTorch Documentation](https://pytorch.org/docs/stable/)

-------------------
### Anaconda setup
You can download Anaconda [here](https://www.anaconda.com/download) and watch a basic tutorial [here](https://freelearning.anaconda.cloud/get-started-with-anaconda).

#### Useful conda commands (on Windows run in Anaconda Prompt):
- conda --version **#** *self-explanatory*
- conda env list **#** *see environments*
- conda list **#** *see installed packages*
- conda create --name example **#** *create environment named *example**
- conda activate example **#** *"move"* to the environment named *example**
- conda install jupyterlab **#** *self-explanatory*
- jupyter-lab ***or*** jupyter lab **#** *opens Jupyter Lab in the folder you are in*
- jupyter notebook **#** *launch Jupyter Notebook*
- conda deactivate **#** *moves to base environment*
- python -m ipykernel install --user --name=example **#** *matches kernel to the environment named *example**
- A lot more [here](https://docs.conda.io/projects/conda/en/latest/_downloads/a35958a2a7fa1e927e7dfb61ebcd69a9/conda-4.14.pdf)

---

### Introduction to tensors

#### **Tensors** are the fundamental building block of machine learning. Their job is to represent data in a numerical way:
A tensor can be just a number, thus having dimension 0, an array, thus having dimension 1, and so on. See graphical example [here](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png).
- `s = torch.tensor(4)` $\Rightarrow$ `s.ndim == 0 && s.shape == torch.Size([])`
- `s = torch.tensor([1,2,3])` $\Rightarrow$ `s.ndim == 1 && s.shape == torch.Size([3])`
- `s = torch.tensor([[1,2,3],[2,3,4]])` $\Rightarrow$ `s.ndim == 2 && s.shape == torch.Size([2,3])`
- `s = torch.tensor([[[1,2,3],[3,6,9],[2,4,5]]])` $\Rightarrow$ `s.ndim == 3 && s.shape == torch.Size([1,3,3])`\
Note: [`ndim`](https://pytorch.org/docs/stable/generated/torch.Tensor.ndim.html?highlight=tensor+ndim#torch.Tensor.ndim) is an alias for [`dim()`](https://pytorch.org/docs/stable/generated/torch.Tensor.dim.html#torch.Tensor.dim)

### Creating tensors

We can create **random** tensors using `torch.rand()`. By default, the datatype is `torch.float32` and the numbers are in the interval `[0,1)`. You can see how to change those and more details [here](https://pytorch.org/docs/stable/generated/torch.rand.html?highlight=rand#torch.rand).

Similarly, you can create tensors full of [**zeros**](https://pytorch.org/docs/stable/generated/torch.zeros.html?highlight=zeros#torch.zeros) (or [**ones**](https://pytorch.org/docs/stable/generated/torch.ones.html?highlight=ones#torch.ones)). You can copy the shape of another tensor but fill it with zeros (or ones) using [`torch.zeros_like()`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like()`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html).

You can also create a 1-D tensor that is populated with an arithmetic progression using the [`torch.arange()`](https://pytorch.org/docs/stable/generated/torch.arange.html?highlight=arange#torch.arange) function.

Examples:

- `torch.rand(2)` $\Rightarrow$ `tensor([0.6185, 0.2044])`
- `torch.rand(size=(2,3))` $\Rightarrow$ `tensor([[0.9920, 0.1177, 0.4073],[0.1193,0.9847,0.1559]])`
- `torch.zeros(2)` $\Rightarrow$ `tensor([0., 0.])`
- `torch.ones(size=(1,2))` $\Rightarrow$ `tensor([[1., 1.]])`
- `zero_to_ten = torch.arange(start=0, end=10, step=1)` $\Rightarrow$ `tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])`
- `torch.zeros_like(input=zero_to_ten)` $\Rightarrow$ `tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])`


### Tensor datatypes

You can explicitly choose the [datatype](https://pytorch.org/docs/stable/tensors.html#data-types) for your tensor using the [attribute `torch.dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype) like this:
```py 
s = torch.tensor([3.0, 6.0, 9.0],dtype=torch.float16)
```
`s.dtype` $\Rightarrow$ `torch.float16`

### Tensor device and size

The [`torch.size(dim=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.size.html?highlight=tensor+size#torch.Tensor.size) method is [equivalent to](https://github.com/pytorch/pytorch/issues/5544) the `torch.shape` attribute of the tensor. If `dim` is specified, `size(int)` returns an int holding the size of that dimension. [`torch.device`](https://pytorch.org/docs/stable/tensor_attributes.html?highlight=device#torch.device) is an object representing where the tensor is or will be allocated. Default is CPU. Here is an example:

```py
t = torch.tensor(data=[[1,2,3]], device='cpu')
print(t.size(),t.device, t.size(1), sep='\n')
```

`torch.Size([1, 3])`\
`cpu`\
`3`

### Basic tensor operations
First of all, you can perform fundamental operations (addition (`+`), subtraction (`-`), mutliplication (`*`)) on tensors like this:
```py
t = torch.tensor([1,  2,  3])
```
- `t += 1` $\Rightarrow$ `t = tensor([[2, 3, 4]])`
- `t -= 1` $\Rightarrow$ `t = tensor([[0, 1, 2]])`
- `t *= 2` $\Rightarrow$ `t = tensor([[2, 4, 6]])`

Note: \
a) `t+1` does not modify `t`; `t=t+1` is required.\
b) division (`/`) works too \
c) Functions [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) and [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) could be used too. Those can add/multiply 2 tensors too like this:
```py
t = torch.tensor([[1,2,3,4]])
w = torch.tensor([[-1],[-2]])
```
`torch.add(t,w)` $\Rightarrow$ `tensor([[0,1,2,3],[-1,0,1,2]])`\
`torch.mul(t,w)` $\Rightarrow$ `tensor([[-1,-2,-3,-4],[-2,-4,-6,-8]])`

### Matrix multiplication
Matrix multiplication can be performed using [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul), [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=mm#torch.mm) or operator `@` (which is equivalent to `matmul`). The difference between `mm` and `matmul` is that `matmul` performs [broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html) while `mm` doesn't.
```py
a = torch.randn(2,3,3)
b = torch.randn(3,2)
```
`torch.mm(a,b)` $\Rightarrow$ runtime error (RE)\
`torch.matmul(a,b).size()` $\Rightarrow$ `torch.Size([2, 3, 2])`
Note: \
a) `torch.mm()` only accepts 2D tensors\
b) [`torch.randn`](https://pytorch.org/docs/stable/generated/torch.randn.html?highlight=randn#torch.randn)\
c) `torch.matmul()` (and `@`) can also perform *dot product*, *matrix-vector product* and *batched matrix multiplication*
```py
a = torch.tensor([1,2])
b = torch.tensor([[-1,-2],[-3,-4]])
```
`b@a` $\Rightarrow$ `tensor([-5,-11])` \
Note that if `a` would have an extra pair of square brackets (`a = torch.tensor([[1,2]])`), `b@a` would cause a RE. `a@b` would work though.

### Tensor transpose
If the tensor is 2D (a matrix), you can access its transpose via [`tensor.T`](https://pytorch.org/docs/stable/tensors.html?highlight=tensor+t#torch.Tensor.T), but this actually works for any kind of tensor. You can also transpose (swap) only 2 given dimensions using the [`torch.transpose(input,dim0,dim1)`](https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose) function. [`torch.t(input)`](https://pytorch.org/docs/stable/generated/torch.t.html#torch.t) also works for tensors with at most 2 dimensions. [tensor.mT](https://pytorch.org/docs/stable/tensors.html?highlight=tensor+mt#torch.Tensor.mT) returns a view of `tensor` with the last two dimensions transposed (equivalent to `x.transpose(-2,  -1)`).
```py
b = torch.randn(40,30,20)
m = torch.nn.Linear(20,30)
m(b).size()
```
`torch.Size([40, 30, 30])`

### Change tensor datatype
Examples are self-explanatory.
```py
a = torch.tensor([2,3,2])
a.dtype
```
$\Rightarrow$ `torch.int64`
```py
b = a.type(torch.float32)
b.dtype
```
$\Rightarrow$ `torch.float32`

### Reshape, stack, squeeze, unsqueeze and permute tensors
- [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) reshapes  `input`  to  `shape`  (if compatible), can also use  `torch.Tensor.reshape()`.
- [`torch.Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html#torch.Tensor.view) returns a view of the original tensor in a different  `shape`  but shares the same data as the original tensor. (similar to `reshape`, doesn't allocate new memory but doesn't always work)
- [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) concatenates a sequence of  `tensors`  along a new dimension (`dim`), all  `tensors`  must be same size.
- [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) squeezes  `input`  to remove all the dimensions with value `1`.
- [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) returns  `input`  with a dimension value of  `1`  added at  `dim`.
- [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) returns a  _view_  of the original  `input`  with its dimensions permuted (rearranged) to  `dims`. **Note**: Because permuting returns a _view_ (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original.

### Selecting data from tensors
It's easier to learn via examples:
```py
x  =  torch.arange(1, 10).reshape(1, 3, 3)
(x, x.shape)
```
```cpp
(tensor([[[1, 2, 3],
          [4, 5, 6],
          [7, 8, 9]]]),
 torch.Size([1, 3, 3]))
```
---
```py
print(f"First square bracket:\n{x[0]}")
print(f"Second square bracket: {x[0][0]}")
print(f"Third square bracket: {x[0][0][0]}")
```
```
First square bracket: tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
Second square bracket: tensor([1, 2, 3]) 
Third square bracket: 1
```
<!--stackedit_data:
eyJoaXN0b3J5IjpbMzQxNjkwOTc5LDE2MjIzMjMxMDUsMTYyMj
MyMzEwNSwxMTQxMDczODA0LDIwNDE1MzkyNDQsLTYzMjUzMTQ1
NywtMTI1MDU4ODI3NSwyMDc2ODU3NjM4LC03MjA0MTYxMzgsLT
MwNDEyNDkwLC0xMDY4NDk3NTUyLDE4NDAyMjc2NTcsLTk1ODY2
MjY2NCwtMTcxOTkxMzM3NiwtNjY3NDk3NDQ3LC04ODM0NjI0MD
MsLTE3MzExMTczMjEsMTM1MjIwMjI1NSwtMjA2Njg5NDEyNywt
MTM1ODU0NDgwOV19
-->